[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UBAI PRACTICE - CNN",
    "section": "",
    "text": "Python 프로젝트의 일환으로, MNIST 데이터셋을 통해 간단한 CNN 모델을 구현해보도록 하겠습니다.\n해당 프로젝트를 통해 CNN의 기본 작동 방식을 이해할 수 있을 것입니다.\n프로젝트 시작에 앞서, MNIST 데이터셋과 CNN 모델에 대해 간단하게 알아보겠습니다.\n 🎨 MNIST 데이터셋\nMNIST는 숫자 0부터 9까지의 손글씨 이미지를 가지고 있는 데이터셋입니다.\n총 60,000개의 훈련 이미지와 10,000개의 테스트 이미지로 구성되어 있으며, 각 이미지는 28x28 픽셀 크기의 흑백 숫자 이미지입니다.\nMNIST 데이터셋은 손글씨 인식 문제를 해결하기 위한 대표적인 예제로 사용되며, 추가로 다양한 기계 학습 알고리즘의 성능을 평가하는 데 자주 활용되는 데이터셋입니다.\n 🧱 CNN\nCNN(Convolutional Neural Network)은 주로 이미지 처리 분야에서 사용되는 딥러닝 모델입니다.\n여러 개의 컨볼루션 레이어와 풀링 레이어를 사용하여 이미지의 특징을 추출하고, 이를 기반으로 분류 또는 예측 작업을 수행합니다.\nCNN은 특히 이미지 데이터에서 높은 성능을 발휘하며, 이미지 분류, 객체 탐지, 의료 영상 분석 등 다양한 응용 분야에서 널리 사용됩니다.  \n\n1. 배치 파일 생성\n가장 먼저 프로젝트 수행을 위한 배치 파일을 생성해보겠습니다.\n아래의 사항을 본인의 작업(job)에 맞게 입력한 후, 본인이 원하는 파일의 이름을 지정하여 filename.sh 형식으로 파일을 저장합니다. 예를 들어 아래의 Shell 파일을 python_project.sh로 저장합니다.\n파일명이 .sh 형식인지 반드시 확인하세요.\n\n#!/bin/bash\n#SBATCH --nodes=1 \n#SBATCH --partition=gpu2 \n#SBATCH --cpus-per-task=56 \n#SBATCH --gres=gpu:4\n#SBATCH --job-name=UBAIJOB \n#SBATCH -o ./결과값 도출 지정 폴더 이름/jupyter.%N.%j.out  # STDOUT \n#SBATCH -e ./결과값 도출 지정 폴더 이름/jupyter.%N.%j.err  # STDERR\n\necho \"start at:\" `date` \necho \"node: $HOSTNAME\" \necho \"jobid: $SLURM_JOB_ID\" \n\nmodule unload CUDA/11.2.2 \nmodule load cuda/11.8.0\n\npython cnn.py 12 256 'relu'\n\n결과값 도출 지정 폴더 이름을 반드시 지정해주세요. 각각 결과 값 폴더를 따로따로 만들어주거나 아니면 동일 폴더에 지정하셔도 됩니다.\nSTDOUT은 결과 값 출력 파일, STDERR는 결과 값 도출 중 출력 되는 로그 파일입니다. 새 폴더를 만들기 위해서는 디렉토리(directory)에서 오른쪽 버튼을 눌러 새 폴더 만들기 버튼을 클릭하시면 됩니다.\n각 라인들의 의미는 다음과 같습니다.\n✔ #SBATCH --nodes=1\n\n총 필요 노드 수를 지정하는 명령어이며, 노드는 자동으로 컴퓨터가 배정해줍니다.\nnodes=1은 노드를 한 개만 사용하겠다는 의미입니다.\n\n✔ #SBATCH --partition=gpu4\n\n사용할 Partition을 지정하는 명령어입니다.\n\n✔ #SBATCH --cpus-per-task=14\n\n총 필요 코어의 개수를 지정하는 명령어입니다.\n노드는 n개의 코어를 가지며, 사용 노드 1개 당 몇 개의 CPU/GPU 코어를 쓸 것인지를 결정합니다.\n\n✔ #SBATCH --gres=gpu:1\n\n몇 개의 GPU를 사용할 것인지 지정하는 명령어입니다.\nCPU Partition을 선택하신 경우 해당 코드는 지워주셔야 합니다. 해당 코드는 GPU의 개수를 지정하는 명령어이기에, 에러가 발생할 수 있습니다.\n\n✔ #SBATCH --job-name=UBAIJOB\n\n작업 이름을 지정하는 명령어입니다.\n\n✔ echo \"start at:\" 'date'\n\n접속 날짜가 표기됩니다.\n\n✔ echo \"node: $HOSTNAME\"\n\n접속한 노드 번호가 표기됩니다.\n\n✔ echo \"jobid: $SLURM_JOB_ID\"\n\njobid가 표기됩니다.\n\n✔ module ~\n\n원하는 Linux 환경을 구축할 수 있습니다.\n기본적으로 CUDA/11.2.2 실행으로 셋팅되어 있습니다. 지금과 같이 다른 GPU 환경을 원할 경우, 해당 모듈을 unload한 후, 원하는 모듈을 load 합니다.\nGPU 환경을 사용하고 싶은 경우에만 해당하며, GPU 환경을 사용하지 않을 경우(CPU Partition 사용) 지우셔도 무관합니다.\n\n✔ python cnn.py 12 256 'relu'\n\n원하는 Python 파일을 실행합니다.\n실행하려는 파일은 반드시 .py파일의 형태로 존재해야합니다. 위 코드에는 cnn.py로 지정하였습니다.\nPython의 sys 패키지를 이용한 sys.argv로 매개변수를 이용한 실행 방법을 사용하였습니다. 자세한 사항은 sys의 공식문서에서 확인할 수 있습니다.\n파라미터 없이 모델을 실행하고 싶은 경우에는 python {filename}.py로 실행할 수 있습니다.\n\n\n📌 참고사항\n.py 파일에서 sys 패키지를 사용할 경우, 매개변수는 다음과 같이 지정됩니다.\n\nsys.argv[0]: 파일 이름\nsys.argv[n]: 원하는 파라미터 (n은 숫자를 의미합니다.)\n\ncnn.py의 경우, 12 256 'relu'가 각각 sys.argv[1], sys.argv[2], sys.argv[3]으로 지정된 것입니다.\n\n실행에 사용된 cnn.py의 자세한 코드는 여기에서 확인할 수 있습니다. 세부적인 코드는 링크를 참고하세요.\n\n\n\n2. 배치 파일 실행\n배치 파일을 실행하기에 앞서, 본인이 생성했던 Python 가상 환경에 들어와 있는 상태인지 재 확인합니다.\n이후, terminal에 sbatch 명령어를 이용하여 지정한 배치 파일명을 입력 및 실행하세요. 이는 작업(job)을 제출한다는 의미입니다.\n실행 후 나온 결과 값은 작업(job)에 대한 ID이니 꼭 따로 저장하거나 메모해두시기를 요청드립니다.\n\nsbatch filename.sh    # ex) sbatch python_project.sh \n\n\n※ 예시코드인 cnn.py를 정상적으로 실행하기 위해서는 추가 패키지 설치 pip install tensorflow && pip install numpy가 필요합니다.\n\n\n작업(job) 제출이 정상적으로 진행되었다면, STDOUT폴더 안에 OUT 파일이 생성됩니다.\n만일 OUT파일이 생성되지 않았다면, 해당 Partition의 노드에 기존 작업(job)이 모두 할당되어 수행하지 못했을 가능성이 높습니다. 이 경우 terminal에 squeue 명령어를 입력하시고, 본인의 ID를 찾습니다.\n보통 배정이 되어있다면 정상적으로 n001, n002 … 으로 노드에 배정되어 있지만, 배정되지 않았을 경우 ( Resources, Priority )라는 메시지를 볼 수 있습니다. 그런 경우 다른 노드가 일이 끝나는 것을 기다리거나, 해당 파티션이 아닌 다른 파티션을 이용하여 노드를 배정받아야 합니다.\n다른 파티션을 이용하기 위해서는 Partition 목록에서 Partition과 cpus-per-task, gpu 갯수를 Partition에 맞게 수정하여 작업(job)을 다시 제출하셔야 합니다.\n\n이제 STDOUT폴더에 생성된 실행 결과 OUT파일을 확인할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>CNN</span>"
    ]
  },
  {
    "objectID": "cnn.html",
    "href": "cnn.html",
    "title": "cnn.py",
    "section": "",
    "text": "import sys\nimport tensorflow as tf\nimport keras\nimport time \nimport os\n\nfrom tensorflow.python.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nstart = time.time()\n\nimg_rows = 28\nimg_cols = 28\n\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\ninput_shape = (img_rows, img_cols, 1)\nx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32') / 255. # 데이터 정규화 \nx_test = x_test.astype('float32') / 255.  # 데이터 정규화 \n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\nbatch_size = int(sys.argv[2])\nnum_classes = 10\nepochs = int(sys.argv[1])\n\ny_train = keras.utils.to_categorical(y_train, num_classes) # 학습을 위한 원핫벡터로 변경 \ny_test = keras.utils.to_categorical(y_test, num_classes) # 원핫벡터로 변경 \n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten()) # fully connected layer \n# 완전 연결계층의 문제점은 데이터의 형상이 무시된다. \n# conv2d로 이미지의 특성들을 뽑아내고 pooling계층을 이용하여 차원을 감소시킨후 dense layer를 사용하여 감소된 차원의 feature map들을 input으로 하여 효율적 학습을 진행 \nmodel.add(Dense(1000, activation=sys.argv[3]))  # -&gt; Dense Layer와 같은 경우에는 가장 기본적인 층으로서 완전연결계층이다. \nmodel.add(Dropout(0.5)) # 과대적합방지를 위해 사용 \nmodel.add(Dense(num_classes, activation='softmax')) \nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nend = time.time() - start\n\nprint(end)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>cnn.py</span>"
    ]
  }
]